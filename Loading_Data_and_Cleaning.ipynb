{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9655f52b",
   "metadata": {},
   "source": [
    "# 0. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b894a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from meteostat import Point, Daily\n",
    "from sodapy import Socrata\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90b5cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f23242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "DATASET_ID = \"erm2-nwe9\"  # NYC 311 Service Requests ID\n",
    "APP_TOKEN = None          # Optional: Sign up for an app token at NYC Open Data for higher limits\n",
    "\n",
    "def get_311_data(start_date=\"2023-01-01\", end_date=\"2025-01-01\", limit=10000):\n",
    "    \"\"\"\n",
    "    Fetches 311 data using the Socrata API.\n",
    "    \"\"\"\n",
    "    client = Socrata(\"data.cityofnewyork.us\", APP_TOKEN)\n",
    "    \n",
    "    # SoQL Query: Filter by date to avoid crashing memory\n",
    "    # We select key columns to keep the dataframe lean\n",
    "    results = client.get(\n",
    "        DATASET_ID,\n",
    "        where=f\"created_date > '{start_date}' AND created_date < '{end_date}'\",\n",
    "        select=\"unique_key, created_date, complaint_type, latitude, longitude, borough, location_type\",\n",
    "        limit=limit\n",
    "    )\n",
    "    \n",
    "    df = pd.DataFrame.from_records(results)\n",
    "    \n",
    "    # Convert dates to datetime objects immediately\n",
    "    df['created_date'] = pd.to_datetime(df['created_date'])\n",
    "    df['closed_date'] = pd.to_datetime(df['closed_date'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0371d953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nyc_weather(start_year, end_year):\n",
    "    # Coordinates for NYC (Central Park area)\n",
    "    location = Point(40.7831, -73.9712)\n",
    "\n",
    "    start = datetime(start_year, 1, 1)\n",
    "    end = datetime(end_year, 12, 31)\n",
    "\n",
    "    # Fetch daily data\n",
    "    data = Daily(location, start, end)\n",
    "    data = data.fetch()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dad92d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_311 = get_311_data(start_date=\"2023-01-01\", limit=7000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e755f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = get_nyc_weather(2023, 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ae936f",
   "metadata": {},
   "source": [
    "# 1. Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aa9155",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_311 = df_311[df_311.latitude.notnull()]\n",
    "df_311 = df_311[df_311.longitude.notnull()]\n",
    "df_311 = df_311[df_311.descriptor.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c7e372",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_311.complaint_type = df_311.complaint_type.str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3afcc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_OSE(agency):\n",
    "\n",
    "  \"\"\"Takes in an agency name and converts to abbreviated form, if the agency is\n",
    "     the Office of Special Enforcement.\"\"\"\n",
    "\n",
    "  if agency == 'MAYORÃ¢\\x80\\x99S OFFICE OF SPECIAL ENFORCEMENT':\n",
    "      return \"OSE\"\n",
    "  else:\n",
    "      return agency\n",
    "    \n",
    "df_311.agency = df_311.agency.map(lambda agency: update_OSE(agency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3dda4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_noise(complaint):\n",
    "\n",
    "  \"\"\"Takes in an complaint name and updates it, if it is\n",
    "     an unspecified noise complaint.\"\"\"\n",
    "\n",
    "  if complaint == 'Noise':\n",
    "    \n",
    "    return \"Noise - Unspecified\"\n",
    "\n",
    "  else:\n",
    "\n",
    "    return complaint\n",
    "    \n",
    "df_311.complaint_type = df_311.complaint_type.map(\n",
    "    lambda complaint: update_noise(complaint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4217cada",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_311['day'] = [str(i.date()) for i in df_311.created_date]\n",
    "df_311['month'] = [int(i.month) for i in df_311.created_date]\n",
    "df_311['day_of_week'] = [int(i.weekday()) for i in df_311.created_date]\n",
    "df_311['hour'] = [int(i.hour) for i in df_311.created_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f81a8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pattern = r'[-()0-9]'\n",
    "df_311.descriptor = df_311.descriptor.map(lambda x: re.sub(num_pattern, '', x).lower())\n",
    "df_311.descriptor = df_311.descriptor.map(lambda x: re.sub('/', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_311.merge(\n",
    "    df_weather, \n",
    "    left_on=df_311['created_date'].dt.date, # Extracts python date object\n",
    "    right_on=df_weather['time'].dt.date\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844afddf",
   "metadata": {},
   "source": [
    "# 2. Removing rare complaint types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30b45b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df_merged['complaint_type'].value_counts()\n",
    "total_rows = len(df_merged)\n",
    "\n",
    "# 2. Define Thresholds to compare\n",
    "thresh_1pct = total_rows * 0.01   # 1% (Your proposal)\n",
    "thresh_01pct = total_rows * 0.002 # 0.1% (Standard alternative)\n",
    "\n",
    "print(f\"Total Rows: {total_rows:,}\")\n",
    "print(f\"1% Threshold: {int(thresh_1pct):,} rows\")\n",
    "print(f\"0.2% Threshold: {int(thresh_01pct):,} rows\")\n",
    "\n",
    "# 3. Identify what gets dropped\n",
    "drop_1pct = counts[counts < thresh_1pct]\n",
    "drop_01pct = counts[counts < thresh_01pct]\n",
    "\n",
    "print(f\"\\n--- At 1% Threshold ({int(thresh_1pct):,} rows) ---\")\n",
    "print(f\"You would drop {len(drop_1pct)} unique complaint types.\")\n",
    "print(f\"Examples of dropped types: {drop_1pct.index[:5].tolist()}\")\n",
    "print(f\"Total data lost: {drop_1pct.sum():,} rows ({(drop_1pct.sum()/total_rows)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n--- At 0.2% Threshold ({int(thresh_01pct):,} rows) ---\")\n",
    "print(f\"You would drop {len(drop_01pct)} unique complaint types.\")\n",
    "print(f\"Total data lost: {drop_01pct.sum():,} rows ({(drop_01pct.sum()/total_rows)*100:.2f}%)\")\n",
    "\n",
    "# 4. Visual \"Elbow\" Plot\n",
    "# We want to see where the curve flattens out\n",
    "cumulative_percent = counts.cumsum() / total_rows\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(len(counts)), cumulative_percent.values, marker='o', markersize=3)\n",
    "plt.axhline(y=0.95, color='r', linestyle='--', label='95% Data Coverage')\n",
    "plt.title('Cumulative Distribution of Complaint Types')\n",
    "plt.xlabel('Number of Complaint Types (Ranked by Volume)')\n",
    "plt.ylabel('Cumulative % of Dataset')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d77cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_count = len(df_merged) * 0.002\n",
    "counts = df_merged['complaint_type'].value_counts()\n",
    "\n",
    "high_volume_types = counts[counts >= threshold_count].index.tolist()\n",
    "\n",
    "whitelist = [\n",
    "    'Snow Or Ice', \n",
    "    'Street Condition', \n",
    "    'Damaged Tree', \n",
    "    'Heat/Hot Water', \n",
    "    'Water Leak', \n",
    "    'Standing Water', \n",
    "    'Sewer'\n",
    "]\n",
    "\n",
    "final_types_to_keep = list(set(high_volume_types + whitelist))\n",
    "\n",
    "df_merged_reduced = df_merged[df_merged['complaint_type'].isin(final_types_to_keep)].copy()\n",
    "\n",
    "print(f\"Original Rows: {len(df_merged):,}\")\n",
    "print(f\"Filtered Rows: {len(df_merged_reduced):,}\")\n",
    "print(f\"Data Retained: {(len(df_merged_reduced)/len(df_merged))*100:.2f}%\")\n",
    "print(f\"Unique Complaint Types: {df_merged_reduced['complaint_type'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ff721",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_reduced = df_merged[df_merged.groupby('complaint_type').complaint_type.transform('count')>13005].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e7005",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_reduced = df_merged_reduced.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54b3099",
   "metadata": {},
   "source": [
    "# 3. Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e9fd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f711f578",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_311.to_csv(f\"{project_dir}/data/311_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58b3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.to_csv(f\"{project_dir}/data/weather_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5f63e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(f\"{project_dir}/data/merged_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f04e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_reduced.to_csv(f\"{project_dir}/data/merged_reduced_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
